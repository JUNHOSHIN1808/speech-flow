import re
import yaml
from pathlib import Path
from typing import Dict, List, Any

import kss
import streamlit as st
import plotly.graph_objects as go
from soynlp.tokenizer import LTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from PyPDF2 import PdfReader

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ë§ì´ë(Speech Flow) ë°œí‘œë¬¸ í”¼ë“œë°± ë³´ì¡° í”„ë¡œê·¸ë¨", page_icon="âœï¸", layout="wide")

# --- ëª¨ë¸ ë° ë¶„ì„ê¸°, ë¶ˆìš©ì–´ ë¡œë“œ (ìºì‹œ ì‚¬ìš©) ---
@st.cache_resource
def get_tokenizer(): 
    # soynlpì˜ LTokenizerëŠ” ëª…ì‚¬ ì¶”ì¶œê³¼ ìœ ì‚¬í•œ íš¨ê³¼ë¥¼ ëƒ…ë‹ˆë‹¤.
    return LTokenizer()

@st.cache_resource
def load_stopwords(filepath):
    stopwords_path = Path(filepath)
    if stopwords_path.exists():
        with open(stopwords_path, 'r', encoding='utf-8') as f:
            return {line.strip() for line in f}
    return set()

tokenizer = get_tokenizer()
STOPWORDS = load_stopwords("stopwords.txt")

# --- í•µì‹¬ ë¶„ì„ í•¨ìˆ˜ë“¤ ---

def analyze_cohesion(text: str, markers: List[str]) -> Dict[str, Any]:
    """í…ìŠ¤íŠ¸ì˜ ì‘ì§‘ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    if not markers: return {"html": text.replace('\n', '<br>'), "markers_list": []}
    
    escaped_markers = [re.escape(marker) for marker in markers]
    pattern = re.compile(r'\b(' + '|'.join(escaped_markers) + r')\b')
    
    def highlight_repl(match): return f'<span class="marker">{match.group(0)}</span>'
    highlighted_text = pattern.sub(highlight_repl, text).replace('\n', '<br>')
    
    return {"html": highlighted_text, "markers_list": markers}

def soynlp_custom_tokenizer(text: str) -> List[str]:
    """soynlp í† í¬ë‚˜ì´ì €ì™€ ë¶ˆìš©ì–´ í•„í„°ë§ì„ ê²°í•©í•œ ë§ì¶¤í˜• í† í¬ë‚˜ì´ì €ì…ë‹ˆë‹¤."""
    tokens = tokenizer.tokenize(text, flatten=True)
    return [tok for tok in tokens if tok not in STOPWORDS and len(tok) > 1]

def extract_keywords(sentences: List[str], top_n: int) -> List[str]:
    """soynlp ë§ì¶¤í˜• í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ TF-IDF ê¸°ë°˜ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if not sentences: return []
    
    try:
        # TfidfVectorizerì— ë§ì¶¤í˜• í† í¬ë‚˜ì´ì €ë¥¼ ì§ì ‘ ì „ë‹¬í•©ë‹ˆë‹¤.
        vectorizer = TfidfVectorizer(
            tokenizer=soynlp_custom_tokenizer,
            min_df=1,
        )
        
        # ì›ë³¸ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì—¬ ë¶„ì„ì˜ ì¼ê´€ì„±ì„ ìœ ì§€í•©ë‹ˆë‹¤.
        tfidf_matrix = vectorizer.fit_transform(sentences)
        
        feature_names = vectorizer.get_feature_names_out()
        total_scores = tfidf_matrix.sum(axis=0).A1
        sorted_indices = total_scores.argsort()[::-1]
        
        # ì´ë¯¸ í† í¬ë‚˜ì´ì € ë‹¨ê³„ì—ì„œ í•„í„°ë§ë˜ì—ˆìœ¼ë¯€ë¡œ, ë°”ë¡œ ìƒìœ„ Nê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        keywords = [feature_names[i] for i in sorted_indices]
        return keywords[:top_n]
    except ValueError: 
        return []

# --- ì¤‘ì‹¬ ë¬¸ì¥ ë¶„ì„ ë¡œì§ ---

def score_all_sentences(paragraph: str, main_topic_list: List[str], markers: List[str], mode: str, config: Dict) -> Dict:
    """í•œ ë¬¸ë‹¨ ë‚´ ëª¨ë“  ë¬¸ì¥ì˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ìƒì„¸ ë‚´ì—­ê³¼ ë¬¸ë‹¨ í•µì‹¬ì–´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    sentences = kss.split_sentences(paragraph)
    if not sentences: return {"scored_sentences": [], "p_keywords": []}
        
    p_keywords = extract_keywords(sentences, 3)
    scored_sentences = []

    if mode == "soft":
        weights = config
        for s in sentences:
            score_breakdown = {'ì£¼ì œì–´': 0.0, 'ë¬¸ë‹¨ í•µì‹¬ì–´': 0.0, 'ë‹´í™” í‘œì§€': 0.0}
            reasons = []
            
            if weights.get('use_main_topic', True) and main_topic_list:
                found_topics = [topic for topic in main_topic_list if topic in s]
                if found_topics:
                    score_breakdown['ì£¼ì œì–´'] = weights.get('main_topic', 1.0) * len(found_topics)
                    reasons.append(f"ì£¼ì œì–´({', '.join(found_topics)})")

            if weights.get('use_p_keyword', True):
                found_kws = [kw for kw in p_keywords if kw in s]
                if found_kws:
                    score_breakdown['ë¬¸ë‹¨ í•µì‹¬ì–´'] = weights.get('p_keyword', 1.0) * len(found_kws)
                    reasons.append(f"ë¬¸ë‹¨í•µì‹¬ì–´({', '.join(found_kws)})")

            if weights.get('use_marker', True):
                found_ms = [m for m in markers if m in s]
                if found_ms:
                    score_breakdown['ë‹´í™” í‘œì§€'] = weights.get('marker', 0.5)
                    reasons.append(f"ë‹´í™”í‘œì§€({', '.join(found_ms)})")
            
            total_score = sum(score_breakdown.values())
            scored_sentences.append({"sentence": s, "score": total_score, "reasons": reasons, "breakdown": score_breakdown})
    
    elif mode == "hard":
        custom_rules = config
        rule_labels = [f"ê·œì¹™ {i+1}: {rule['condition']}" for i, rule in enumerate(custom_rules)]

        for s in sentences:
            breakdown = {label: 0.0 for label in rule_labels}
            
            for i, rule in enumerate(custom_rules):
                condition_met = False
                condition_type = rule['condition']
                value = rule.get('value', '')

                if condition_type == "ì£¼ì œì–´ í¬í•¨":
                    if main_topic_list and any(topic in s for topic in main_topic_list): condition_met = True
                elif condition_type == "ë¬¸ë‹¨ í•µì‹¬ì–´ í¬í•¨":
                    if any(kw in s for kw in p_keywords): condition_met = True
                elif condition_type == "ë‹´í™” í‘œì§€ í¬í•¨":
                    if any(m in s for m in markers): condition_met = True
                elif condition_type == "íŠ¹ì • ë‹¨ì–´ í¬í•¨":
                    if value and value in s: condition_met = True
                elif condition_type == "ë¬¸ì¥ ê¸¸ì´ (ì´ìƒ)":
                    if value and len(s) >= int(value): condition_met = True
                elif condition_type == "ë¬¸ì¥ ê¸¸ì´ (ì´í•˜)":
                    if value and len(s) <= int(value): condition_met = True
                
                if condition_met:
                    action = rule['action']
                    score_value = rule.get('score_value', 1.0)
                    rule_label = rule_labels[i]
                    if action == "ì ìˆ˜ ë”í•˜ê¸°":
                        breakdown[rule_label] += score_value
                    elif action == "ì ìˆ˜ ë¹¼ê¸°":
                        breakdown[rule_label] -= score_value

            total_score = sum(breakdown.values())
            reasons = [f"{key.split(':')[1].strip()}" for key, val in breakdown.items() if val > 0]
            scored_sentences.append({"sentence": s, "score": total_score, "reasons": reasons, "breakdown": breakdown})

    return {"scored_sentences": scored_sentences, "p_keywords": p_keywords}

# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ UI ---
def main():
    st.title("âœï¸ Speech Flow")

    st.markdown("""
    <style>
    .marker { background: #ffeb3b80; padding: 2px 4px; border-radius: 4px; font-weight: bold; }
    .key-sentence { background: #d1e7dd; border-left: 5px solid #198754; padding: 8px 12px; margin: 10px 0; display: block; border-radius: 4px; }
    </style>
    """, unsafe_allow_html=True)

    if 'custom_rules' not in st.session_state:
        st.session_state.custom_rules = [{'condition': 'ì£¼ì œì–´ í¬í•¨', 'action': 'ì ìˆ˜ ë”í•˜ê¸°', 'value': '', 'score_value': 1.0}]
    if 'key_sentences_for_reorder' not in st.session_state:
        st.session_state.key_sentences_for_reorder = []
    if 'soft_config' not in st.session_state:
        st.session_state.soft_config = {
            'use_main_topic': True, 'main_topic': 1.5,
            'use_p_keyword': True, 'p_keyword': 1.0,
            'use_marker': True, 'marker': 0.5
        }

    with st.sidebar:
        st.header("1ï¸âƒ£ ë‹´í™” í‘œì§€ ëª©ë¡ ì„¤ì •")
        default_markers = "ê·¸ëŸ¬ë‚˜\ní•˜ì§€ë§Œ\në”°ë¼ì„œ\nê·¸ëŸ¬ë¯€ë¡œ\nê·¸ë¦¬ê³ \ní•œí¸\nì¦‰\nì˜ˆë¥¼ ë“¤ì–´\nê²°ë¡ ì ìœ¼ë¡œ\në°˜ë©´ì—\në˜í•œ"
        markers_text = st.text_area("í•œ ì¤„ì— í•˜ë‚˜ì”© ë‹´í™” í‘œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", value=default_markers, height=200)
        markers_list = [line.strip() for line in markers_text.split('\n') if line.strip()]

        st.divider()
        st.header("2ï¸âƒ£ ì¤‘ì‹¬ ë¬¸ì¥ ë¶„ì„ ì„¤ì •")
        main_topic_input = st.text_input("ê¸€ì˜ ì£¼ì œì–´ (ì‰¼í‘œë¡œ ì—¬ëŸ¬ ê°œ, ë˜ëŠ” ë¬¸ì¥ ì…ë ¥ ê°€ëŠ¥)", placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥, ë¯¸ë˜").strip()
        
        main_topic_list = []
        if main_topic_input:
            if ',' in main_topic_input:
                main_topic_list = [word.strip() for word in main_topic_input.split(',') if word.strip()]
            else:
                # ë¬¸ì¥ìœ¼ë¡œ ì…ë ¥ ì‹œ, ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë§Œ ì¶”ì¶œ (soynlp ì‚¬ìš©)
                tokens = tokenizer.tokenize(main_topic_input, flatten=True)
                main_topic_list = [t for t in tokens if t not in STOPWORDS and len(t) > 1]
        
        if main_topic_list:
            st.caption(f"ë¶„ì„ì— ì ìš©ë  ì£¼ì œì–´: `{', '.join(main_topic_list)}`")

        analysis_mode = st.radio(
            "ë¶„ì„ ë°©ì‹ ì„ íƒ",
            ["ê°„í¸ ì„¤ì •", "ê·œì¹™ ë¹Œë” (ê³ ê¸‰)"],
            captions=["ê°„ë‹¨í•œ ê°€ì¤‘ì¹˜ ì¡°ì ˆ ë°©ì‹", "IF-THEN ê·œì¹™ ì§ì ‘ ì¡°ë¦½"]
        )
        
        if analysis_mode == "ê°„í¸ ì„¤ì •":
            st.session_state.soft_config['use_main_topic'] = st.checkbox("ì£¼ì œì–´ í¬í•¨ ì—¬ë¶€", value=st.session_state.soft_config['use_main_topic'], key="soft_main")
            st.session_state.soft_config['main_topic'] = st.number_input("ì£¼ì œì–´ ê°€ì¤‘ì¹˜", min_value=0.0, value=st.session_state.soft_config['main_topic'], step=0.1, key="soft_main_w")
            st.session_state.soft_config['use_p_keyword'] = st.checkbox("ë¬¸ë‹¨ í•µì‹¬ì–´ í¬í•¨ ì—¬ë¶€", value=st.session_state.soft_config['use_p_keyword'], key="soft_p")
            st.session_state.soft_config['p_keyword'] = st.number_input("ë¬¸ë‹¨ í•µì‹¬ì–´ ê°€ì¤‘ì¹˜", min_value=0.0, value=st.session_state.soft_config['p_keyword'], step=0.1, key="soft_p_w")
            st.session_state.soft_config['use_marker'] = st.checkbox("ë‹´í™” í‘œì§€ í¬í•¨ ì—¬ë¶€", value=st.session_state.soft_config['use_marker'], key="soft_m")
            st.session_state.soft_config['marker'] = st.number_input("ë‹´í™” í‘œì§€ ê°€ì¤‘ì¹˜", min_value=0.0, value=st.session_state.soft_config['marker'], step=0.1, key="soft_m_w")

        else: # "ê·œì¹™ ë¹Œë” (ê³ ê¸‰)"
            for i, rule in enumerate(st.session_state.custom_rules):
                st.markdown(f"---")
                cols = st.columns([4, 4, 1])
                with cols[0]:
                    rule['condition'] = st.selectbox("IF (ì¡°ê±´)", ["ì£¼ì œì–´ í¬í•¨", "ë¬¸ë‹¨ í•µì‹¬ì–´ í¬í•¨", "ë‹´í™” í‘œì§€ í¬í•¨", "íŠ¹ì • ë‹¨ì–´ í¬í•¨", "ë¬¸ì¥ ê¸¸ì´ (ì´ìƒ)", "ë¬¸ì¥ ê¸¸ì´ (ì´í•˜)"], key=f"cond_{i}")
                    if "íŠ¹ì • ë‹¨ì–´" in rule['condition']: rule['value'] = st.text_input("ë‹¨ì–´", key=f"val_word_{i}")
                    elif "ë¬¸ì¥ ê¸¸ì´" in rule['condition']: rule['value'] = st.number_input("ê¸€ì ìˆ˜", min_value=1, value=50, key=f"val_len_{i}")
                with cols[1]:
                    rule['action'] = st.selectbox("THEN (ì‹¤í–‰)", ["ì ìˆ˜ ë”í•˜ê¸°", "ì ìˆ˜ ë¹¼ê¸°"], key=f"act_{i}")
                    if "ì ìˆ˜" in rule['action']: rule['score_value'] = st.number_input("ì ìˆ˜", min_value=0.1, value=1.0, step=0.1, key=f"val_score_{i}")
                with cols[2]:
                    st.write(""); st.write("")
                    if st.button("âŒ", key=f"del_{i}"):
                        st.session_state.custom_rules.pop(i)
                        st.rerun()
            if st.button("â• ìƒˆ ê·œì¹™ ì¶”ê°€"):
                st.session_state.custom_rules.append({'condition': 'ì£¼ì œì–´ í¬í•¨', 'action': 'ì ìˆ˜ ë”í•˜ê¸°', 'value': '', 'score_value': 1.0})
                st.rerun()

    st.header("1ï¸âƒ£ í…ìŠ¤íŠ¸ ì…ë ¥")
    st.info("ì•„ë˜ì— í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ë¶™ì—¬ë„£ê±°ë‚˜, .txt ë˜ëŠ” .pdf íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    uploaded_file = st.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=['txt', 'pdf'])
    
    file_content = ""
    if uploaded_file is not None:
        try:
            if uploaded_file.type == "text/plain":
                file_content = uploaded_file.getvalue().decode("utf-8")
            elif uploaded_file.type == "application/pdf":
                pdf_reader = PdfReader(uploaded_file)
                for page in pdf_reader.pages:
                    file_content += page.extract_text() + "\n"
        except Exception as e:
            st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    default_text = file_content if file_content else ""
    text_input = st.text_area("ë¶„ì„í•  í…ìŠ¤íŠ¸", value=default_text, height=300)
    
    run_button = st.button("ë¶„ì„ ì‹¤í–‰", type="primary")

    if run_button:
        if not text_input:
            st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return

        with st.spinner("í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            cohesion_result = analyze_cohesion(text_input, markers_list)
            
            st.divider()
            st.subheader("ğŸ“ ë‹´í™”í‘œì§€ í•˜ì´ë¼ì´íŠ¸")
            st.markdown(cohesion_result['html'], unsafe_allow_html=True)

            st.divider()
            st.subheader("ğŸ“ ì¤‘ì‹¬ ë¬¸ì¥ ë¶„ì„ ê²°ê³¼")
            st.caption(f"ë¶„ì„ ëª¨ë“œ: **{analysis_mode}** | ì ìš©ëœ ì£¼ì œì–´: **`{', '.join(main_topic_list)}`**")

            st.session_state.key_sentences_for_reorder = []
            
            paragraphs = [p.strip() for p in re.split(r'\n+', text_input.strip()) if p.strip()]
            
            for i, para in enumerate(paragraphs):
                mode = "soft" if analysis_mode == "ê°„í¸ ì„¤ì •" else "hard"
                current_config = st.session_state.soft_config if mode == "soft" else st.session_state.custom_rules
                
                analysis_result = score_all_sentences(para, main_topic_list, markers_list, mode, current_config)
                all_scored_sentences = analysis_result["scored_sentences"]
                p_keywords = analysis_result["p_keywords"]
                
                st.markdown(f"**ë¬¸ë‹¨ {i+1}**")
                if p_keywords:
                    st.markdown(f"> **ë¬¸ë‹¨ í•µì‹¬ì–´:** `{'`, `'.join(p_keywords)}`")

                if all_scored_sentences:
                    best_sentence_info = max(all_scored_sentences, key=lambda x: x['score'])
                    
                    if best_sentence_info['score'] > 0:
                        st.session_state.key_sentences_for_reorder.append(best_sentence_info['sentence'])
                        highlighted_paragraph = para.replace(best_sentence_info['sentence'], f"<div class='key-sentence'>{best_sentence_info['sentence']}</div>")
                        st.markdown(highlighted_paragraph, unsafe_allow_html=True)
                        
                        breakdown = best_sentence_info['breakdown']
                        details = [f"{key.split(':')[1].strip() if ':' in key else key}({val:.1f})" for key, val in breakdown.items() if val > 0]
                        st.caption(f"ì„ ì • ì´ìœ : {' + '.join(details)} (ì´ì : {best_sentence_info['score']:.2f})")

                        with st.expander("ë¬¸ë‹¨ ë‚´ ë¬¸ì¥ë³„ ì ìˆ˜ ìƒì„¸ ë³´ê¸°"):
                            for k, s_info in enumerate(all_scored_sentences):
                                s_breakdown = s_info['breakdown']
                                s_details = [f"{key.split(':')[1].strip() if ':' in key else key}({val:.1f})" for key, val in s_breakdown.items() if val > 0]
                                if not s_details:
                                    st.write(f"_{k+1}ë²ˆì§¸ ë¬¸ì¥: (ì ìˆ˜ ì—†ìŒ)_")
                                else:
                                    st.write(f"**{k+1}ë²ˆì§¸ ë¬¸ì¥ (ì´ì : {s_info['score']:.2f}):** {' + '.join(s_details)}")
                            
                            st.markdown("---")
                            st.markdown("##### ë¬¸ì¥ë³„ ì ìˆ˜ ë¹„êµ ê·¸ë˜í”„")
                            sentences_labels = [f"{j+1}ë²ˆì§¸" for j in range(len(all_scored_sentences))]
                            all_rule_names = sorted(list(set(key for s in all_scored_sentences for key in s['breakdown'].keys())))
                            breakdown_data = {name: [s['breakdown'].get(name, 0) for s in all_scored_sentences] for name in all_rule_names}
                            
                            fig = go.Figure()
                            for name, data in breakdown_data.items():
                                fig.add_trace(go.Bar(name=name, x=sentences_labels, y=data))
                            fig.update_layout(barmode='stack', title_text='ë¬¸ì¥ë³„ ì ìˆ˜ êµ¬ì„±', xaxis_title="ë¬¸ì¥", yaxis_title="ì ìˆ˜")
                            st.plotly_chart(fig, use_container_width=True)

                    else:
                        st.markdown(para)
                        st.caption("ì¤‘ì‹¬ ë¬¸ì¥ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.markdown(para)
                    st.caption("ë¶„ì„í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown("---")

    if st.session_state.key_sentences_for_reorder:
        st.divider()
        st.subheader("âœ¨ í•µì‹¬ ë¬¸ì¥ êµ¬ì¡°í™”")
        st.info("ì¶”ì¶œëœ í•µì‹¬ ë¬¸ì¥ë“¤ì˜ ìˆœì„œì™€ ì—­í• ì„ ì¬êµ¬ì„±í•˜ì—¬ ê¸€ì˜ ìµœì¢… ë¼ˆëŒ€ë¥¼ ì™„ì„±í•˜ì„¸ìš”.")

        num_sentences = len(st.session_state.key_sentences_for_reorder)

        for i in range(num_sentences):
            cols = st.columns([2, 8, 1, 1, 1])
            
            role = ""
            if i == 0: role = "ë„ì…"
            elif i == num_sentences - 1 and num_sentences > 1: role = "ë§ˆë¬´ë¦¬"
            else: role = f"ì „ê°œ {i}"
            
            cols[0].markdown(f"### {role}")

            user_input = cols[1].text_area(f"ë¬¸ì¥ {i+1} í¸ì§‘", value=st.session_state.key_sentences_for_reorder[i], label_visibility="collapsed", key=f"reorder_text_{i}")
            st.session_state.key_sentences_for_reorder[i] = user_input
            
            if cols[2].button("ğŸ”¼", key=f"up_{i}", help="ìœ„ë¡œ ì´ë™") and i > 0:
                st.session_state.key_sentences_for_reorder.insert(i-1, st.session_state.key_sentences_for_reorder.pop(i))
                st.rerun()

            if cols[3].button("ğŸ”½", key=f"down_{i}", help="ì•„ë˜ë¡œ ì´ë™") and i < num_sentences - 1:
                st.session_state.key_sentences_for_reorder.insert(i+1, st.session_state.key_sentences_for_reorder.pop(i))
                st.rerun()
            
            if cols[4].button("ğŸ—‘ï¸", key=f"del_{i}", help="ì‚­ì œ"):
                st.session_state.key_sentences_for_reorder.pop(i)
                st.rerun()

        if st.button("â• ìƒˆ ë¬¸ì¥ ì¶”ê°€"):
            st.session_state.key_sentences_for_reorder.append("ì—¬ê¸°ì— ìƒˆë¡œìš´ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”.")
            st.rerun()
            
        st.markdown("---")
        
        st.subheader("ê²°ê³¼ ë‚´ë³´ë‚´ê¸°")
        
        final_text_lines = []
        for i, sentence in enumerate(st.session_state.key_sentences_for_reorder):
            role = ""
            if i == 0: role = "ë„ì…"
            elif i == len(st.session_state.key_sentences_for_reorder) - 1 and len(st.session_state.key_sentences_for_reorder) > 1: role = "ë§ˆë¬´ë¦¬"
            else: role = f"ì „ê°œ {i}"
            final_text_lines.append(f"[{role}] {sentence}")

        final_text = "\n\n".join(final_text_lines)
        
        st.text_area("ë³µì‚¬í•˜ê¸°", value=final_text, height=150)
        
        st.download_button(
            label="í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ (.txt)",
            data=final_text.encode('utf-8'),
            file_name='structured_summary.txt',
            mime='text/plain',
        )

if __name__ == "__main__":
    main()
